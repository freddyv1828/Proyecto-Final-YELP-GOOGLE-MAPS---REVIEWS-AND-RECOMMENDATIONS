{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificación de datos\n",
    "\n",
    "El objetivo de este Notebook, será unificar los datos que vienen esparcidos en varios JSON en distintas carpetas proporcionadas, esto con el objetivo de poder trabajar en un solo DataFrame todos los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_7876\\4128522967.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # Trabajaremos datos con Pandas.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Trabajaremos datos con Pandas.\n",
    "import os # Trabajaremos con las carpetas del sistema operativo con OS.\n",
    "import json # Leeremos los archivos en grupo con json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unificamos los datos en un solo DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Función para leer carpetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para nuestro objetivo, el cual será leer cada archivo JSON dentro de las carpetas y retornar un DataFrame unificado de todos ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_carpeta(path):\n",
    "    '''\n",
    "    Leer una carpeta de Json.\n",
    "\n",
    "    Lee los archivos JSON de una carpeta, y los unifica en un solo DataFrame de pandas.\n",
    "\n",
    "    Requiere importar:\n",
    "    pandas\n",
    "    json\n",
    "    os\n",
    "\n",
    "    Recibe:\n",
    "    La ruta hacia una carpeta que contenga archivos JSON.\n",
    "\n",
    "    Retorna:\n",
    "    Un DataFrame de todos los JSON.\n",
    "    '''\n",
    "    total_data = [] # Guardamos los datos que vayamos leyendo.\n",
    "    # Iteramos en la carpeta.\n",
    "    for file in os.listdir(path):\n",
    "        filepath = os.path.join(path, file) # Creamos la ruta hacia el archivo sobre el que estamos iterando.\n",
    "        with open(filepath, 'r') as f: # Abrimos el archivo.\n",
    "            for line in f: # Iteramos sobre sus lineas\n",
    "                data = json.loads(line) # Extraemos la linea como un JSON.\n",
    "                total_data.append(data) # Guardamos el JSON en una lista.\n",
    "    return pd.DataFrame(total_data) # Creamos un DataFrame con los datos finales y lo retornamos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Leemos cada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = '../../Data/Google/review-' # Ruta base a la cual le agregaremos el nombre del estado que usaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal = leer_carpeta(mainpath + 'California') # Leemos la carpeta agregando el nombre del estado y lo almacenamos en un DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previsualizamos la estructura del DataFrame para tener una guía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2700000 entries, 0 to 2699999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   user_id  object\n",
      " 1   name     object\n",
      " 2   time     int64 \n",
      " 3   rating   int64 \n",
      " 4   text     object\n",
      " 5   pics     object\n",
      " 6   resp     object\n",
      " 7   gmap_id  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 164.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cal.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperamos tener los 3 DataFrames con 8 columnas, y aproximadamente 2,700,000 registros, debemos verificar que las columnas de este DataFrame coincidan con las de los de otros estados para hacer una unión correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los demás DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flo = leer_carpeta(mainpath + 'Florida')\n",
    "df_nev = leer_carpeta(mainpath + 'Nevada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Verificación de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que tengan las mismas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_cal.columns # Tomamos uno de los dfs para usar sus columnas como guía.\n",
    "for colev in (df_nev.columns, df_flo.columns):\n",
    "    if colev.equals(cols): # Comparamos las columnas de cada df con las del ejemplo, si alguna no coincide, lo hacemos saber.\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Las columnas {colev} no coinciden con {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Unión vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas son las mismas, así que hacemos una unión vertical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_cal, df_flo, df_nev], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7350000 entries, 0 to 1799999\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   user_id  object\n",
      " 1   name     object\n",
      " 2   time     int64 \n",
      " 3   rating   int64 \n",
      " 4   text     object\n",
      " 5   pics     object\n",
      " 6   resp     object\n",
      " 7   gmap_id  object\n",
      "dtypes: int64(2), object(6)\n",
      "memory usage: 504.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos las filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df_cal.shape[0] + df_nev.shape[0] + df_flo.shape[0]\n",
    "if df.shape[0] != total: # Verificamos que las filas del DataFrame resultante sean la suma de las filas de los 3 que unimos.\n",
    "    print(\"Faltan filas en el DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Exportamos los datos para su uso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../../Data/Google/reviews_merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
